{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations with WindGym Environments\n",
    "\n",
    "This notebook provides a comprehensive guide to running simulations in WindGym, focusing on the core environment classes: `WindFarmEnv` and `FarmEval`. We'll explore their differences, intended use cases, and how to interact with them for both single-agent and multi-agent scenarios.\n",
    "\n",
    "## 1. Core WindGym Environments: `WindFarmEnv` vs. `FarmEval`\n",
    "\n",
    "WindGym offers two primary environment classes for different simulation needs:\n",
    "\n",
    "1.  **`WindFarmEnv`**: The base, general-purpose environment.\n",
    "2.  **`FarmEval`**: A specialized subclass of `WindFarmEnv` designed specifically for evaluation and fixed-condition simulations.\n",
    "\n",
    "Understanding their relationship and distinctions is crucial for effective use of WindGym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `WindFarmEnv`: The Flexible Base Environment\n",
    "\n",
    "`WindFarmEnv` is your go-to environment for general-purpose wind farm simulations. It's designed to be flexible, supporting various configurations and dynamic wind conditions, making it suitable for:\n",
    "\n",
    "* **Reinforcement Learning Training**: Agents can learn to adapt to changing wind conditions over long episodes.\n",
    "* **Stochastic Wind Sampling**: It can integrate with PyWake `Site` objects (`sample_site` parameter) to sample realistic wind speeds and directions based on wind resource distributions (e.g., Weibull for speed, frequency for direction). If `sample_site` is not provided, it samples uniformly from defined min/max ranges.\n",
    "* **Dynamic Changes**: While this version primarily uses steady wind within an episode, `WindFarmEnv`'s architecture allows for future extensions that could introduce wind changes mid-episode.\n",
    "* **Multi-Agent Foundation**: It serves as the base for the `WindFarmEnvMulti` environment (discussed later) for decentralized control problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `FarmEval`: The Evaluation-Focused Environment\n",
    "\n",
    "`FarmEval` is a direct subclass of `WindFarmEnv` (`class FarmEval(WindFarmEnv):`). It inherits all capabilities of `WindFarmEnv` but **overrides key behaviors** to facilitate precise and reproducible evaluations under specific, controlled conditions. Its main features include:\n",
    "\n",
    "* **Fixed Wind Conditions**: `FarmEval` allows you to *directly set* the wind speed (`ws`), wind direction (`wd`), and turbulence intensity (`ti`) via `set_wind_vals()` *before* calling `reset()`. This overrides any stochastic sampling, ensuring the environment always starts with the exact specified wind conditions.\n",
    "* **Evaluation Loop Compatibility**: It is specifically used by the `AgentEval` class (and its `eval_single_fast` function) for running standardized benchmarks, as demonstrated later in this notebook.\n",
    "* **Non-Terminating Episodes**: By default, `FarmEval` episodes are \"infinite\" (or very long, set by `time_max = 9999999`) unless `finite_episode=True` is explicitly set. This ensures that evaluation runs for a consistent duration without premature termination.\n",
    "* **Baseline Comparison**: It often enables the `Baseline_comp=True` flag by default or is configured to always run a parallel baseline simulation for direct comparison of agent performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Differences Summary\n",
    "\n",
    "| Feature                  | `WindFarmEnv`                                        | `FarmEval`                                                 |\n",
    "| :----------------------- | :--------------------------------------------------- | :--------------------------------------------------------- |\n",
    "| **Base Class** | `gymnasium.Env`                                      | `WindFarmEnv`                                              |\n",
    "| **Primary Use** | RL Training, General Simulation (stochastic wind)    | Fixed-condition Evaluation, Benchmarking                   |\n",
    "| **Wind Conditions** | Randomly sampled (from ranges or `sample_site`)      | Explicitly set via `set_wind_vals()` (overrides sampling) |\n",
    "| **Episode Length** | Defined by `n_passthrough`, can terminate/truncate   | Effectively 'infinite' by default (`time_max` overwritten) |\n",
    "| **`reset()` behavior** | Samples new wind unless overridden                   | Uses explicitly set wind conditions                        |\n",
    "| **Stochasticity** | High (wind sampling, turbulence generation)          | Controlled (fixed wind for evaluation)                     |\n",
    "| **Parameter Setting** | Parameters set during initialization (`__init__`)    | Parameters can be explicitly set/overridden via methods    |\n",
    "\n",
    "---\n",
    "\n",
    "Now, let's start by setting up the necessary imports and a `config.yaml` file that both environments will use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup: Imports and Configuration File\n",
    "\n",
    "We'll need common Python libraries and specific WindGym components. We'll also define a `config.yaml` file, which specifies various environment parameters like observation details, reward functions, and action methods. Ensure this `config.yaml` is saved in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import yaml\n",
    "import xarray as xr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import WindGym environment classes\n",
    "from WindGym.Wind_Farm_Env import WindFarmEnv\n",
    "from WindGym.FarmEval import FarmEval\n",
    "from WindGym.AgentEval import eval_single_fast\n",
    "from WindGym.Agents import PyWakeAgent, RandomAgent\n",
    "from WindGym.WindEnvMulti import WindFarmEnvMulti\n",
    "\n",
    "# Import a default turbine model from PyWake\n",
    "from py_wake.examples.data.hornsrev1 import V80, Hornsrev1Site # Hornsrev1Site for stochastic wind example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `config.yaml` Content\n",
    "\n",
    "Create a file named `config.yaml` in the same directory as this notebook with the following content. This file defines the detailed behavior of the WindGym environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This cell is for display purposes only. \n",
    "# You should create a physical file named 'config.yaml' with this content.\n",
    "config_yaml_content = \"\"\"\n",
    "yaw_init: \"Zeros\"\n",
    "noise: \"None\"\n",
    "BaseController: \"Local\"\n",
    "ActionMethod: \"wind\"\n",
    "Track_power: False\n",
    "act_pen:\n",
    "  action_penalty: 0.0\n",
    "  action_penalty_type: \"Change\"\n",
    "power_def:\n",
    "  Power_scaling: 1000000000.0\n",
    "  Power_avg: 50\n",
    "  Power_reward: \"Baseline\"\n",
    "mes_level:\n",
    "  turb_ws: True\n",
    "  turb_wd: True\n",
    "  turb_TI: False\n",
    "  turb_power: True\n",
    "  farm_ws: True\n",
    "  farm_wd: True\n",
    "  farm_TI: False\n",
    "  farm_power: True\n",
    "  ti_sample_count: 30\n",
    "ws_mes:\n",
    "  ws_current: False\n",
    "  ws_rolling_mean: True\n",
    "  ws_history_N: 1\n",
    "  ws_history_length: 10\n",
    "  ws_window_length: 10\n",
    "wd_mes:\n",
    "  wd_current: False\n",
    "  wd_rolling_mean: True\n",
    "  wd_history_N: 1\n",
    "  wd_history_length: 10\n",
    "  wd_window_length: 10\n",
    "yaw_mes:\n",
    "  yaw_current: False\n",
    "  yaw_rolling_mean: True\n",
    "  yaw_history_N: 2\n",
    "  yaw_history_length: 30\n",
    "  yaw_window_length: 1\n",
    "power_mes:\n",
    "  power_current: False\n",
    "  power_rolling_mean: True\n",
    "  power_history_N: 1\n",
    "  power_history_length: 10\n",
    "  power_window_length: 10\n",
    "farm:\n",
    "  yaw_min: -45\n",
    "  yaw_max: 45\n",
    "wind:\n",
    "  ws_min: 8.0\n",
    "  ws_max: 12.0\n",
    "  TI_min: 0.07\n",
    "  TI_max: 0.15\n",
    "  wd_min: 260.0\n",
    "  wd_max: 280.0\n",
    "\"\"\"\n",
    "\n",
    "# Write the content to config.yaml if it doesn't exist\n",
    "yaml_path = 'config.yaml'\n",
    "if not os.path.exists(yaml_path):\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        f.write(config_yaml_content)\n",
    "    print(f\"Created '{yaml_path}' with default content.\")\n",
    "else:\n",
    "    print(f\"'{yaml_path}' already exists. Using existing file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic `WindFarmEnv` Usage: Training Environment\n",
    "\n",
    "Let's demonstrate how to initialize and interact with the base `WindFarmEnv`. This environment is typically used for training Reinforcement Learning agents, where wind conditions might vary from episode to episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define turbine positions (e.g., two turbines placed along the x-axis)\n",
    "x_pos_base = np.array([0, 500])  # Meters\n",
    "y_pos_base = np.array([0, 0])    # Meters\n",
    "\n",
    "# Initialize the WindFarmEnv\n",
    "env = WindFarmEnv(\n",
    "    turbine=V80(),              # The wind turbine model to use\n",
    "    x_pos=x_pos_base,           # X-coordinates of the turbines\n",
    "    y_pos=y_pos_base,           # Y-coordinates of the turbines\n",
    "    n_passthrough=5,            # Simulate for 5 \"flow passthroughs\" to define episode length\n",
    "    dt_sim=1,                   # Internal simulation timestep in seconds (e.g., DWM solver step)\n",
    "    dt_env=5,                   # Environment timestep in seconds (how often the agent acts)\n",
    "                                # dt_env must be a multiple of dt_sim\n",
    "    yaw_step_sim=1,             # Maximum 1 degree yaw change per dt_sim\n",
    "    yaml_path=yaml_path,        # Path to the YAML configuration file\n",
    "    Baseline_comp=True,         # Enable a parallel baseline farm for comparison\n",
    "    render_mode=None,           # Set to 'human' for visualization, 'None' for headless operation\n",
    "    seed=42                     # Random seed for reproducibility\n",
    ")\n",
    "\n",
    "print(f\"Initialized WindFarmEnv: Observation Space {env.observation_space}, Action Space {env.action_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with `WindFarmEnv`: `reset()` and `step()`\n",
    "\n",
    "The standard Gymnasium API (`reset()` and `step()`) is used for interaction.\n",
    "\n",
    "#### Resetting the Environment\n",
    "\n",
    "`env.reset()` initializes a new episode. In `WindFarmEnv`, this involves sampling new global wind conditions (speed, direction, turbulence intensity) within the ranges defined in `config.yaml`, setting up a turbulence field, initializing turbine yaw angles, and running a \"burn-in\" period to stabilize the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the environment to start a new episode\n",
    "observation, info = env.reset()\n",
    "\n",
    "print(\"\\n--- Initial State of WindFarmEnv ---\")\n",
    "print(\"Initial Observation (scaled between -1 and 1):\\n\", observation)\n",
    "print(\"\\nInitial Info Dictionary (contains raw values and metadata):\")\n",
    "for key, value in info.items():\n",
    "    if isinstance(value, np.ndarray):\n",
    "        print(f\"  {key}: shape={value.shape}, dtype={value.dtype}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nInitial Wind Conditions for this episode: WS={info['Wind speed Global']:.2f} m/s, WD={info['Wind direction Global']:.2f} deg, TI={info['Turbulence intensity']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking Steps (`env.step()`)\n",
    "\n",
    "In each `step()`, your agent provides an `action` (a NumPy array scaled between -1 and 1), and the environment returns the `next_observation`, `reward`, `terminated` flag, `truncated` flag, and an updated `info` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 5 # Number of environment steps to simulate\n",
    "\n",
    "print(f\"\\nRunning {num_steps} steps in WindFarmEnv with random actions...\")\n",
    "for i in range(num_steps):\n",
    "    # Check if the episode has ended\n",
    "    if info.get('terminated', False) or info.get('truncated', False):\n",
    "        print(f\"Episode ended at step {i}.\\n\")\n",
    "        break\n",
    "\n",
    "    # Sample a random action from the environment's action space\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # Take a step in the environment with the sampled action\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    print(f\"\\n--- Step {i+1} ---\")\n",
    "    print(f\"Action (raw): {action}\")\n",
    "    print(f\"Reward: {reward:.4f}\")\n",
    "    print(f\"Farm Power (Agent): {info['Power agent'] / 1e6:.2f} MW\")\n",
    "    if 'Power baseline' in info: # Baseline power is only available if Baseline_comp is True\n",
    "        print(f\"Farm Power (Baseline): {info['Power baseline'] / 1e6:.2f} MW\")\n",
    "    print(f\"Current Yaw Angles (Agent): {np.round(info['yaw angles agent'], 2)}\")\n",
    "    print(f\"Time: {info['time_array'][-1]:.2f} s\")\n",
    "    \n",
    "print(\"\\nClosing WindFarmEnv...\")\n",
    "env.close()\n",
    "print(\"WindFarmEnv closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running Simulations with `FarmEval`: Evaluation and Pre-built Agents\n",
    "\n",
    "`FarmEval` is ideal for reproducible evaluations under fixed wind conditions, which is crucial for benchmarking and comparing different agents. Here, we'll use it to evaluate a `PyWakeAgent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define turbine positions for a small farm for evaluation (e.g., three turbines in a row)\n",
    "x_pos_eval = np.array([0, 600, 1200]) # meters\n",
    "y_pos_eval = np.array([0, 0, 0])      # meters\n",
    "\n",
    "# Initialize the FarmEval environment\n",
    "eval_env = FarmEval(\n",
    "    turbine=V80(),\n",
    "    x_pos=x_pos_eval,\n",
    "    y_pos=y_pos_eval,\n",
    "    dt_sim=1,\n",
    "    dt_env=10,\n",
    "    yaw_step_sim=1,\n",
    "    yaml_path=yaml_path,\n",
    "    Baseline_comp=True,     # Essential for comparing agent to a baseline\n",
    "    render_mode=None,       # Typically headless for evaluations to speed up\n",
    "    seed=42,\n",
    "    # For fixed wind condition evaluation, ensure sample_site is None.\n",
    "    # The wind conditions are set directly via eval_env.set_wind_vals().\n",
    "    sample_site=None,\n",
    ")\n",
    "\n",
    "# Set specific, fixed wind conditions for this evaluation run BEFORE resetting\n",
    "eval_env.set_wind_vals(ws=10.0, ti=0.07, wd=270.0)\n",
    "\n",
    "# Initialize the PyWakeAgent\n",
    "# The PyWakeAgent calculates optimal yaw angles based on the current wind conditions\n",
    "pywake_agent = PyWakeAgent(\n",
    "    x_pos=x_pos_eval,\n",
    "    y_pos=y_pos_eval,\n",
    "    turbine=V80(),\n",
    "    env=eval_env # Pass the environment object to the agent for context\n",
    ")\n",
    "\n",
    "print(\"\\n--- Running simulation with PyWakeAgent using eval_single_fast ---\")\n",
    "# eval_single_fast runs a full episode with the specified agent and returns an xarray Dataset\n",
    "# t_sim specifies the total simulation time in seconds\n",
    "eval_results = eval_single_fast(\n",
    "    env=eval_env,\n",
    "    model=pywake_agent,\n",
    "    ws=10.0,\n",
    "    ti=0.07,\n",
    "    wd=270.0,\n",
    "    t_sim=6,     \n",
    "    save_figs=False,        # Set to True to generate frame-by-frame plots (can be very slow)\n",
    "    debug=False,\n",
    "    deterministic=True,     # Use deterministic policy for the agent\n",
    "    name=\"PyWake_3Turbines_Test\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single wind speed, direction, and TI for plotting, assuming eval_results has these dimensions\n",
    "selected_data = eval_results.sel(ws=10.0, wd=270.0, TI=0.07, method='nearest')\n",
    "#print(selected_data['powerF_a'].head())\n",
    "\n",
    "# Access the underlying data for plotting, and use .squeeze() to remove singleton dimensions\n",
    "agent_power = selected_data['powerF_a'].squeeze().values \n",
    "baseline_power = selected_data['powerF_b'].squeeze().values \n",
    "time_steps = selected_data['time'].values\n",
    "\n",
    "agent_yaw_all_turbines = selected_data['yaw_a'].squeeze().values\n",
    "baseline_yaw_all_turbines = selected_data['yaw_b'].squeeze().values\n",
    "\n",
    "front_turbine_idx = np.argmin(x_pos_eval)\n",
    "back_turbine_idx = np.argmax(x_pos_eval)\n",
    "\n",
    "# One for power, one for front turbine yaw, one for back turbine yaw\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 12), sharex=True) # Increased figsize for 3 plots\n",
    "\n",
    "# Plot 1: Farm Power Output\n",
    "ax1.plot(time_steps, agent_power / 1e6, label='PyWake Agent Power (MW)')\n",
    "ax1.plot(time_steps, baseline_power / 1e6, label='Baseline Power (MW)', linestyle='--')\n",
    "ax1.set_ylabel('Farm Power (MW)')\n",
    "ax1.set_title(f'Farm Performance (WS={selected_data.ws.item()}m/s, WD={selected_data.wd.item()}deg, TI={selected_data.TI.item()})')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Front Turbine Yaw Angle\n",
    "ax2.plot(time_steps, agent_yaw_all_turbines[:, front_turbine_idx], label=f'PyWake Agent Yaw (Turbine {front_turbine_idx+1})', color='purple')\n",
    "ax2.plot(time_steps, baseline_yaw_all_turbines[:, front_turbine_idx], label=f'Baseline Yaw (Turbine {front_turbine_idx+1})', color='purple', linestyle=':')\n",
    "ax2.set_ylabel('Yaw Angle (degrees)')\n",
    "ax2.set_title(f'Front Turbine Yaw Angles (Turbine {front_turbine_idx+1})') # Specific title\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend() # Local legend for this plot\n",
    "\n",
    "# Plot 3: Back Turbine Yaw Angle\n",
    "ax3.plot(time_steps, agent_yaw_all_turbines[:, back_turbine_idx], label=f'PyWake Agent Yaw (Turbine {back_turbine_idx+1})', color='green')\n",
    "ax3.plot(time_steps, baseline_yaw_all_turbines[:, back_turbine_idx], label=f'Baseline Yaw (Turbine {back_turbine_idx+1})', color='green', linestyle=':')\n",
    "ax3.set_ylabel('Yaw Angle (degrees)')\n",
    "ax3.set_xlabel('Time (s)') # Label x-axis only on the bottom-most plot\n",
    "ax3.set_title(f'Back Turbine Yaw Angles (Turbine {back_turbine_idx+1})') # Specific title\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend() # Local legend for this plot\n",
    "\n",
    "# Adjust layout to prevent overlapping titles/labels\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nClosing FarmEval environment...\")\n",
    "eval_env.close() # Important: close the evaluation environment to release resources\n",
    "print(\"FarmEval environment closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Agent Simulations (`WindFarmEnvMulti`)\n",
    "\n",
    "WindGym also supports multi-agent environments, where each turbine can be controlled by an independent agent. This is achieved using `WindFarmEnvMulti`, which wraps `WindFarmEnv` to conform to the [PettingZoo Parallel API](https://pettingzoo.farama.org/api/parallel/).\n",
    "\n",
    "In this setup:\n",
    "* Each turbine is considered a separate 'agent'.\n",
    "* `reset()` and `step()` methods return dictionaries where keys are agent IDs (e.g., `'turbine_0'`, `'turbine_1'`).\n",
    "* Actions provided to `step()` must also be a dictionary with agent IDs as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define turbine positions for a multi-agent farm (e.g., three turbines)\n",
    "# x_pos_multi = np.array([0, 500, 1000]) # 3 turbines for multi-agent setup\n",
    "# y_pos_multi = np.array([0, 0, 0])\n",
    "\n",
    "# # Initialize the multi-agent environment\n",
    "# multi_env = WindFarmEnvMulti(\n",
    "#     turbine=V80(),\n",
    "#     n_passthrough=5,\n",
    "#     dt_sim=1,\n",
    "#     dt_env=5,\n",
    "#     yaw_step=1,             # Note: This is now `yaw_step` in multi-agent env,\n",
    "#                             # representing the max yaw change per env step for all turbines\n",
    "#     yaml_path=yaml_path,\n",
    "#     Baseline_comp=False,    # Baseline comparison is typically handled externally for multi-agent setups\n",
    "#     render_mode=None,\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "# # Optional: Test PettingZoo API compliance (uncomment to run)\n",
    "# # This will run a series of checks on your environment to ensure it adheres to the PettingZoo API.\n",
    "# # from pettingzoo.test import parallel_api_test # You'd need to install pettingzoo to run this\n",
    "# # print(\"\\n--- Running PettingZoo API test for WindFarmEnvMulti ---\")\n",
    "# # parallel_api_test(multi_env, num_cycles=100)\n",
    "# # print(\"PettingZoo API test passed!\")\n",
    "\n",
    "# # Reset the multi-agent environment to start a new episode\n",
    "# observations, infos = multi_env.reset()\n",
    "\n",
    "# # Initialize an agent for each possible turbine in the environment\n",
    "# # The `agents` dictionary maps each agent_id (e.g., 'turbine_0') to its corresponding agent object.\n",
    "# agents = {agent_id: RandomAgent(env=multi_env) for agent_id in multi_env.possible_agents}\n",
    "# print(f\"\\nInitialized {len(agents)} agents: {list(agents.keys())}\")\n",
    "\n",
    "# num_steps_multi = 5\n",
    "# print(f\"\\nRunning {num_steps_multi} multi-agent steps...\")\n",
    "\n",
    "# for i in range(num_steps_multi):\n",
    "#     actions = {}\n",
    "#     # Each active agent determines its action\n",
    "#     for agent_id in multi_env.agents: # Iterate over active agents (those not terminated/truncated)\n",
    "#         # Agents take actions based on their individual observation.\n",
    "#         # For simplicity, RandomAgent doesn't use the observation for its decision.\n",
    "#         action, _ = agents[agent_id].predict(observations[agent_id])\n",
    "#         actions[agent_id] = action\n",
    "\n",
    "#     # Step the multi-agent environment with actions from all active agents\n",
    "#     observations, rewards, terminations, truncations, infos = multi_env.step(actions)\n",
    "\n",
    "#     print(f\"\\n--- Multi-Agent Step {i+1} ---\")\n",
    "#     print(f\"Actions: {actions}\")\n",
    "#     print(f\"Rewards: {rewards}\")\n",
    "#     print(f\"Terminations: {terminations}\")\n",
    "#     print(f\"Truncations: {truncations}\")\n",
    "#     # Example of accessing info for a specific agent (uncomment to see output)\n",
    "#     # if 'turbine_0' in infos:\n",
    "#     #     print(f\"Agent 0 Yaw: {infos['turbine_0']['yaw angles agent']:.2f} deg\")\n",
    "\n",
    "#     # Check if all agents have terminated or truncated\n",
    "#     if all(terminations.values()) or all(truncations.values()):\n",
    "#         print(f\"Multi-agent episode ended at step {i+1}.\\n\")\n",
    "#         break\n",
    "\n",
    "# print(\"\\nClosing Multi-Agent environment...\")\n",
    "# multi_env.close()\n",
    "# print(\"Multi-Agent environment closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
